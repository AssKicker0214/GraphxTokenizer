# 使用Spark Graphx 进行分词
## 重要部分简介
### GraphxCreator
首先你需要一些语料，将他们存进mongodb。
这里，我将一定量语料拆为两个部分，分别作为**训练集**和**测试集**，
对应的数据库集合为`train`和`test`。结构为`_id`（整形），`text`（字符串，保存句子）

> 1. 你完全没有必要将这些语料拆为**训练集**和**测试集**。我所用的分词方法可以理解为
一种非监督的学习。

> 2. 建议句子不要太长，会严重影响执行速度。建议对一大段话事先拆分成短句。


`GraphxCreator` 会对语料生成一个模型，这个模型的形式是图。
然后将这个图存入mongodb。其结构为`src_name`（一个字），`des_name`（另一个字），`weight`（两个字边的权重，即出现频数）

### GraphxCutter
`train`,`test`,`train_edges`就是所有我们需要的数据准备。分词步骤如下：
1. 从`test`读取待分词的句子
2. 将这些句子中的字连接起来，构成一个有向图，记为*图A*。每一条链（连通分量）代表一个句子
3. 从`train_edges`读取之前生成的模型，记为*图B*
4. 将*图B*中的边权重，对应的填入*图A*
5. 对*图A*做迭代(pregel),将每一个字标为 A/B/E/I 中的一种
6. 输出分词后的文本文件。

|标记|含义|
| --- | --- |
| A | 代表一句话的第一个字 |
| B | 代表一个词的第一个字，词的开头|
| I | 代表一个这个字属于一个词 |
| E | 代表一个词的结尾 |

> ***注意*** B（E）是当前字是一个词开头（结尾）的**充分条件**。
也就是说，会出现 IIBIB 的情况，这时，第2个字是结尾，第4个也是结尾。
这样设计的原因是为了节省Graphx的迭代时间